{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2403470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fe00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_text(img_path):\n",
    "    ''' loads an image and recognizes text. '''\n",
    "    \n",
    "    reader = easyocr.Reader(['en'])        # For English - 'en'  And,  For Hindi - 'hi'\n",
    "    return reader.readtext(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec47ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = recognize_text(\"image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the current(Selected) image\n",
    "img_1 = cv2.imread(\"IMG_2174.jpg\")\n",
    "img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834cdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_ocr_text(img_path, save_name):\n",
    "    ''' loads an image, recognize text, and overlays the tet on the image. '''\n",
    "    \n",
    "    # Load images\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    dpi = 80\n",
    "    fig_width, fig_height = int(img.shape[0]/dpi), int(img.shape[1]/dpi)\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(1,2, figsize=(fig_width, fig_height))\n",
    "    axarr[0].imshow(img)\n",
    "    \n",
    "    # Recognise text\n",
    "    result = recognize_text(img_path)\n",
    "    \n",
    "    # If OCR prob is over 0.2, overlay bounding box and text\n",
    "    for(bbox, text, prob) in result:\n",
    "        if prob >= 0.2:\n",
    "            print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            \n",
    "            # get top-left and bottom-right bbox vertices\n",
    "            (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "            top_left = (int(top_left[0]), int(top_left[1]))\n",
    "            bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "            \n",
    "            # create a rectangle for bbox display\n",
    "            cv2.rectangle(img=img, pt1=top_left, pt2=bottom_right, color=(255,0,0), thickness=10)\n",
    "            \n",
    "            # put recogized text\n",
    "            cv2.putText(img=img, text=text, org=(top_left[0], top_left[1] - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,0,0), thickness=8)\n",
    "            \n",
    "    # show and save image\n",
    "    axarr[1].imshow(img)\n",
    "    plt.savefig(f'./output/{save_name}_overlay.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_ocr_text(\"IMG_2174.jpg\", 'Text_Output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
